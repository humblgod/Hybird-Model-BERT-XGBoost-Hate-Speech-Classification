# Hybrid-Model-BERT-XGBoost-Hate-Speech-Classification

This project is a research-based implementation of a **hybrid model combining BERT and XGBoost** for hate speech classification. It was developed as part of my undergraduate thesis to explore how effective hybrid modeling can be in detecting hate speech in textual data.

## üß† Project Overview

The aim of this project is to evaluate the performance of hybrid machine learning models‚Äîspecifically **BERT (Bidirectional Encoder Representations from Transformers)** and **XGBoost (Extreme Gradient Boosting)**‚Äîon hate speech classification tasks. By combining the power of deep contextual embeddings with robust tree-based classification, the project seeks to improve the detection of offensive or harmful language.

## üõ†Ô∏è Tech Stack

- **Programming Language**: Python
- **Notebook Environment**: Jupyter Notebook
- **Core Libraries**:
  - `transformers`
  - `scikit-learn`
  - `xgboost`
  - `numpy`
  - `pandas`
  - `matplotlib`
  - `seaborn`

## üöÄ How to Run

1. **Clone the Repository**
   ```bash
   git clone https://github.com/yourusername/Hybrid-Model-BERT-XGBoost-Hate-Speech-Classification.git
   cd Hybrid-Model-BERT-XGBoost-Hate-Speech-Classification
